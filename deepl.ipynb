{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"Batch_2_train_labels_clean.csv\")\n",
    "df2 = pd.read_csv(\"Batch_1_train_labels_clean.csv\")\n",
    "\n",
    "df3 = pd.read_excel(\"image_labels_batch_3.xlsx\")\n",
    "df4 = pd.read_excel(\"image_labels_batch_4.xlsx\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  image_name           category  \\\n",
      "0       image_874729307_product_74244625.jpg          PC Gaming   \n",
      "1       image_874730792_product_49132716.jpg           Nintendo   \n",
      "2       image_874731199_product_74093483.jpg        PlayStation   \n",
      "3       image_874731370_product_49948298.jpg           Nintendo   \n",
      "4      image_881487935_product_126111824.jpg           Nintendo   \n",
      "..                                       ...                ...   \n",
      "346  image_1100063096_product_1711731907.jpg          PC Gaming   \n",
      "347  image_1100063685_product_1711736000.jpg          PC Gaming   \n",
      "348  image_1100064358_product_1711734478.jpg          PC Gaming   \n",
      "349  image_1119523636_product_2000192031.jpg  Réalité Virtuelle   \n",
      "350  image_1139162966_product_2379124886.jpg           Nintendo   \n",
      "\n",
      "               subcategory  \n",
      "0                  Jeux PC  \n",
      "1    Jeux Game Boy Advance  \n",
      "2                 Jeux PS3  \n",
      "3    Jeux Game Boy Advance  \n",
      "4         Jeux Nintendo DS  \n",
      "..                     ...  \n",
      "346                Jeux PC  \n",
      "347                Jeux PC  \n",
      "348                Jeux PC  \n",
      "349             Jeux VR PC  \n",
      "350       Jeux Nintendo DS  \n",
      "\n",
      "[351 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Charger le DataFrame contenant les informations des images et des labels\n",
    "# df = pd.read_csv(\"ton_fichier.csv\")  # Assure-toi que df est déjà chargé dans ton environnement (avec les colonnes \"image_name\" et \"category\")\n",
    "\n",
    "# Définir le dossier contenant les images\n",
    "image_dir = \"Projet_3/batchs_équilibrés/batch_entrainement/\"\n",
    "\n",
    "# Fonction pour charger une image et son label avec TensorFlow\n",
    "def load_image(img_name, label):\n",
    "    # Construire le chemin complet de l'image avec tf.strings.join\n",
    "    img_path = tf.strings.join([image_dir, img_name])  # Joindre le répertoire et le nom de l'image\n",
    "    img = tf.io.read_file(img_path)  # Lire l'image avec TensorFlow\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # Décoder l'image (JPEG) en un Tensor\n",
    "    img = tf.image.resize(img, [224, 224])  # Redimensionner l'image à 224x224\n",
    "    img = img / 255.0  # Normalisation des pixels entre 0 et 1\n",
    "    return img, label\n",
    "\n",
    "# Convertir les noms d'images et labels en TensorFlow Dataset\n",
    "image_names = df[\"image_name\"].values\n",
    "labels = df[\"category_encoded\"].values\n",
    "\n",
    "# Créer un dataset TensorFlow à partir des chemins d'images et des labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_names, labels))\n",
    "\n",
    "# Appliquer la fonction de chargement d'image et label avec map\n",
    "dataset = dataset.map(lambda x, y: load_image(x, y))\n",
    "\n",
    "# Diviser en batchs, mélanger et pré-charger pour améliorer les performances\n",
    "dataset = dataset.batch(32).shuffle(1000).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x92 in position 191: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Entraîner le modèle\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Sauvegarder le modèle\u001b[39;00m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x92 in position 191: invalid start byte"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Définir le modèle CNN (Convolutional Neural Network)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(np.unique(labels)), activation='softmax')  # Nombre de classes\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(dataset, epochs=10)\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "model.save(\"model.h5\")\n",
    "\n",
    "# Affichage des résultats de l'entraînement\n",
    "print(\"Entraînement terminé. Le modèle a été sauvegardé sous 'model.h5'.\")\n",
    "\n",
    "# Si tu souhaites visualiser l'historique de l'entraînement, voici comment :\n",
    "# Vérifier que les clés 'loss' et 'accuracy' existent dans l'historique\n",
    "if 'accuracy' in history.history:\n",
    "    acc = history.history['accuracy']\n",
    "else:\n",
    "    acc = history.history['accuracy_1']  # Selon la version de TensorFlow, ça peut être accuracy_1\n",
    "\n",
    "# Tracer la courbe de perte\n",
    "plt.plot(history.history['loss'], label='Perte (loss)')\n",
    "plt.plot(acc, label='Précision (accuracy)')\n",
    "plt.title(\"Courbes de l'entraînement\")\n",
    "plt.xlabel(\"Époques\")\n",
    "plt.ylabel(\"Valeur\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 194: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Compiler et tester l'entraînement avec un modèle plus simple\u001b[39;00m\n\u001b[0;32m     82\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 84\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Sauvegarder le modèle\u001b[39;00m\n\u001b[0;32m     88\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 194: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Lire les fichiers CSV en utilisant un encodage correct\n",
    "try:\n",
    "    df1 = pd.read_csv(\"Batch_2_train_labels_clean.csv\", encoding='utf-8')\n",
    "    df2 = pd.read_csv(\"Batch_1_train_labels_clean.csv\", encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df1 = pd.read_csv(\"Batch_2_train_labels_clean.csv\", encoding='utf-8', errors='ignore')\n",
    "    df2 = pd.read_csv(\"Batch_1_train_labels_clean.csv\", encoding='utf-8', errors='ignore')\n",
    "\n",
    "df3 = pd.read_excel(\"image_labels_batch_3.xlsx\", engine='openpyxl')\n",
    "df4 = pd.read_excel(\"image_labels_batch_4.xlsx\", engine='openpyxl')\n",
    "\n",
    "# Fusionner les DataFrames\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "\n",
    "# Encoder les catégories en valeurs numériques\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "# Définir le dossier contenant les images\n",
    "image_dir = \"batchs_équilibrés\\\\batch_entrainement - Copie\\\\\"\n",
    "\n",
    "\n",
    "def load_image(img_name, label):\n",
    "    try:\n",
    "        # Utiliser tf.py_function pour s'assurer que l'on travaille avec une chaîne et non un tenseur\n",
    "        img_name_str = tf.py_function(lambda x: x.numpy().decode('utf-8'), [img_name], Tout=tf.string)\n",
    "\n",
    "        img_path = tf.strings.join([image_dir, img_name_str])  # Construire le chemin complet\n",
    "        img = tf.io.read_file(img_path)  # Lire l'image\n",
    "        img = tf.image.decode_jpeg(img, channels=3)  # Décoder l'image\n",
    "        img = tf.image.resize(img, [224, 224])  # Redimensionner l'image\n",
    "        img = img / 255.0  # Normaliser l'image\n",
    "        return img, label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement de l'image {img_name}: {e}\")\n",
    "        return tf.zeros([224, 224, 3]), label  # Retourner une image vide au lieu de None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def filter_invalid_images(img, label):\n",
    "    \"\"\"Filtrer les images invalides.\"\"\"\n",
    "    return img is not None\n",
    "\n",
    "# Convertir les noms d'images et labels en TensorFlow Dataset\n",
    "image_names = df[\"image_name\"].values\n",
    "labels = df[\"category_encoded\"].values\n",
    "\n",
    "# Créer un dataset TensorFlow à partir des chemins d'images et des labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_names, labels))\n",
    "\n",
    "# Appliquer la fonction de chargement d'image et label avec map\n",
    "dataset = dataset.map(lambda x, y: load_image(x, y))\n",
    "\n",
    "# Filtrer les images invalides\n",
    "dataset = dataset.filter(filter_invalid_images)\n",
    "\n",
    "# Diviser en batchs, mélanger et pré-charger pour améliorer les performances\n",
    "dataset = dataset.batch(32).shuffle(1000).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Modèle simplifié pour tester\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(len(np.unique(labels)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiler et tester l'entraînement avec un modèle plus simple\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(dataset, epochs=1)\n",
    "\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "model.save(\"model.h5\")\n",
    "\n",
    "# Affichage des résultats de l'entraînement\n",
    "print(\"Entraînement terminé. Le modèle a été sauvegardé sous 'model.h5'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérification des fichiers dans batchs_équilibrés\\batch_entrainement\\ :\n",
      "['image_1000493202_product_353771692.jpg', 'image_1004469307_product_299520596.jpg', 'image_1016066453_product_493545596.jpg', 'image_1025231310_product_436182917.jpg', 'image_1027953365_product_301940235.jpg', 'image_1027961004_product_578256383.jpg', 'image_1032783160_product_630642988.jpg', 'image_1039267141_product_646789701.jpg', 'image_1041335988_product_825941638.jpg', 'image_1041415174_product_826453416.jpg', 'image_1041748138_product_832656848.jpg', 'image_1044577992_product_861269059.jpg', 'image_1049879107_product_957011147.jpg', 'image_1051593_product_1283013.jpg', 'image_1053085531_product_1022623650.jpg', 'image_1053259382_product_1028931562.jpg', 'image_1053519738_product_1033730640.jpg', 'image_1058972548_product_1089685811.jpg', 'image_1062523736_product_301815907.jpg', 'image_1068150012_product_1132613553.jpg', 'image_1068227670_product_1190608934.jpg', 'image_1068342_product_3108655.jpg', 'image_1073717173_product_1324193385.jpg', 'image_1075005845_product_1139865005.jpg', 'image_1077931399_product_1029033291.jpg', 'image_1096911277_product_1638225913.jpg', 'image_1098376627_product_1684789300.jpg', 'image_1100059921_product_1711736573.jpg', 'image_1100059985_product_1711729477.jpg', 'image_1100062722_product_1711729209.jpg', 'image_1100063685_product_1711736000.jpg', 'image_1100064150_product_1711734470.jpg', 'image_1100065101_product_1711733299.jpg', 'image_1100065729_product_1711730415.jpg', 'image_1100065974_product_1711736557.jpg', 'image_1100066181_product_1711734926.jpg', 'image_1100066237_product_1711735656.jpg', 'image_1100066257_product_1711735869.jpg', 'image_1100066292_product_1711728922.jpg', 'image_1100066810_product_1711736554.jpg', 'image_1100066842_product_1711728920.jpg', 'image_1100068625_product_1711735034.jpg', 'image_1100069166_product_1711734525.jpg', 'image_1100070218_product_1711734642.jpg', 'image_1100070334_product_1711733251.jpg', 'image_1100071411_product_1711730412.jpg', 'image_1100073107_product_1711735590.jpg', 'image_1100073842_product_1711735498.jpg', 'image_1100076011_product_1711736387.jpg', 'image_1100076297_product_1711730104.jpg', 'image_1100076669_product_1711736594.jpg', 'image_1100076852_product_1711728854.jpg', 'image_1100077047_product_1711736577.jpg', 'image_1100077500_product_1711734807.jpg', 'image_1100077520_product_1711736784.jpg', 'image_1100077574_product_1711735833.jpg', 'image_1100077949_product_1711736055.jpg', 'image_1100081021_product_1711736636.jpg', 'image_1100081308_product_1711735062.jpg', 'image_1100081813_product_1711736882.jpg', 'image_1100081873_product_1711736649.jpg', 'image_1100081963_product_1711731563.jpg', 'image_1100082443_product_1711730037.jpg', 'image_1100083267_product_1711729062.jpg', 'image_1100083741_product_1711736282.jpg', 'image_1100085244_product_1711736828.jpg', 'image_1100086947_product_1711736338.jpg', 'image_1102674938_product_1805032545.jpg', 'image_110307330_product_1198135.jpg', 'image_1108215009_product_1871867473.jpg', 'image_1108316109_product_1874931038.jpg', 'image_1108365016_product_1875756839.jpg', 'image_1108365346_product_1875804585.jpg', 'image_1108365418_product_1875756849.jpg', 'image_1108365425_product_1875804608.jpg', 'image_1108737984_product_1878218298.jpg', 'image_1108738672_product_1878218172.jpg', 'image_1108738842_product_1878218230.jpg', 'image_1108738856_product_1878218295.jpg', 'image_1110810102_product_1904422813.jpg', 'image_1115683575_product_1949003999.jpg', 'image_1116698200_product_1963983036.jpg', 'image_1117041866_product_1967323837.jpg', 'image_1119523636_product_2000192031.jpg', 'image_1121512302_product_2032256097.jpg', 'image_1123495532_product_1936795860.jpg', 'image_1123660911_product_2060555800.jpg', 'image_1130418886_product_2184281904.jpg', 'image_1132925383_product_2237358098.jpg', 'image_1132983627_product_2240360476.jpg', 'image_1132983697_product_2240360489.jpg', 'image_1132983863_product_2240360521.jpg', 'image_1133950997_product_2034871712.jpg', 'image_1134177075_product_2275732341.jpg', 'image_1134618245_product_2287962051.jpg', 'image_1139162966_product_2379124886.jpg', 'image_1141465108_product_2432859218.jpg', 'image_1142916338_product_3910575.jpg', 'image_1143577545_product_2467914465.jpg', 'image_1146083530_product_2151614761.jpg', 'image_1146981061_product_2527236596.jpg', 'image_1148926787_product_2550005949.jpg', 'image_1149450149_product_2036108212.jpg', 'image_1152030349_product_2596981190.jpg', 'image_1158045210_product_2694313750.jpg', 'image_1159838466_product_2720289759.jpg', 'image_1159838467_product_2720289758.jpg', 'image_1160912325_product_2726077368.jpg', 'image_1161168397_product_2733520304.jpg', 'image_1168313731_product_2856775404.jpg', 'image_1176898982_product_2964292933.jpg', 'image_1176954743_product_2965041516.jpg', 'image_1178140299_product_2807747392.jpg', 'image_1183024584_product_3010870346.jpg', 'image_1186985707_product_3040901566.jpg', 'image_1187911797_product_3058415833.jpg', 'image_1195977838_product_3179266037.jpg', 'image_1196604463_product_3108206564.jpg', 'image_1199617908_product_3233258914.jpg', 'image_1211700782_product_3250210074.jpg', 'image_1215651393_product_3471354509.jpg', 'image_1225786777_product_3592267416.jpg', 'image_1231976657_product_3656477301.jpg', 'image_1233470015_product_3626367914.jpg', 'image_1234513943_product_3684576397.jpg', 'image_1234808632_product_3690853420.jpg', 'image_1235567047_product_3695632560.jpg', 'image_1236934329_product_3716121060.jpg', 'image_1236934770_product_3716121141.jpg', 'image_1236934931_product_3716121410.jpg', 'image_1236934944_product_3716121425.jpg', 'image_1236935361_product_3716121933.jpg', 'image_1236944545_product_3716248639.jpg', 'image_1240554261_product_3748316863.jpg', 'image_1241398257_product_3756587883.jpg', 'image_1246419210_product_3797495566.jpg', 'image_1247153473_product_3805769836.jpg', 'image_1268084489_product_3906702928.jpg', 'image_1268253920_product_1585204775.jpg', 'image_1268904663_product_3947920720.jpg', 'image_1280048988_product_4042765839.jpg', 'image_1285449640_product_4042892616.jpg', 'image_1301143063_product_4150865160.jpg', 'image_1302204660_product_4154117441.jpg', 'image_1315355210_product_4205293139.jpg', 'image_1315763371_product_4206711456.jpg', 'image_13233030_product_1431728.jpg', 'image_134067230_product_2920625.jpg', 'image_234303430_product_6648556.jpg', 'image_251865378_product_7980077.jpg', 'image_283812671_product_15511645.jpg', 'image_300773669_product_2532960.jpg', 'image_300917069_product_928105.jpg', 'image_301844443_product_5189935.jpg', 'image_30320630_product_1663769.jpg', 'image_308038846_product_1607404.jpg', 'image_319050191_product_46845576.jpg', 'image_324151298_product_14034577.jpg', 'image_328927145_product_927741.jpg', 'image_334877360_product_47896567.jpg', 'image_347816633_product_48336271.jpg', 'image_381381976_product_49628162.jpg', 'image_438013740_product_48575623.jpg', 'image_476359610_product_1853453.jpg', 'image_476581624_product_2990280.jpg', 'image_529140_product_923202.jpg', 'image_54547530_product_929584.jpg', 'image_558592269_product_53702264.jpg', 'image_564455330_product_49848465.jpg', 'image_583198100_product_54284822.jpg', 'image_622938810_product_1172613.jpg', 'image_62364030_product_1559752.jpg', 'image_62369530_product_2242928.jpg', 'image_652832876_product_53217499.jpg', 'image_659698_product_822774.jpg', 'image_659788_product_1018391.jpg', 'image_689615053_product_56875966.jpg', 'image_689649164_product_184794.jpg', 'image_712678422_product_1586816.jpg', 'image_716950448_product_7490474.jpg', 'image_729787_product_1069161.jpg', 'image_77378530_product_1511251.jpg', 'image_79506330_product_2628871.jpg', 'image_821752779_product_62539070.jpg', 'image_834625716_product_2922066.jpg', 'image_845665195_product_74697205.jpg', 'image_846014108_product_75096137.jpg', 'image_846909214_product_76281501.jpg', 'image_847403454_product_76335437.jpg', 'image_848934197_product_80184781.jpg', 'image_848934236_product_80184839.jpg', 'image_848934532_product_80185024.jpg', 'image_849650304_product_81124208.jpg', 'image_852972374_product_80220190.jpg', 'image_854179052_product_85756666.jpg', 'image_857279564_product_2922637.jpg', 'image_858267336_product_80597800.jpg', 'image_858283719_product_92572816.jpg', 'image_862620327_product_102967842.jpg', 'image_867095986_product_55556886.jpg', 'image_871216205_product_115839088.jpg', 'image_871483952_product_115419768.jpg', 'image_873763964_product_119565640.jpg', 'image_873981549_product_119753971.jpg', 'image_874237655_product_119941493.jpg', 'image_874537621_product_107645356.jpg', 'image_874538053_product_111847660.jpg', 'image_874538275_product_105665622.jpg', 'image_874538397_product_111096070.jpg', 'image_874714971_product_1766378.jpg', 'image_874726355_product_50692880.jpg', 'image_874727855_product_99505596.jpg', 'image_874727878_product_90062129.jpg', 'image_874728161_product_82614930.jpg', 'image_874728237_product_60669170.jpg', 'image_874728473_product_82088950.jpg', 'image_874728837_product_97517744.jpg', 'image_874729026_product_77765803.jpg', 'image_874729307_product_74244625.jpg', 'image_874729653_product_65150348.jpg', 'image_874729700_product_51838314.jpg', 'image_874730026_product_46615098.jpg', 'image_874730352_product_82272428.jpg', 'image_874730792_product_49132716.jpg', 'image_874730967_product_71079705.jpg', 'image_874731199_product_74093483.jpg', 'image_874731282_product_76560739.jpg', 'image_874731286_product_46704360.jpg', 'image_874731370_product_49948298.jpg', 'image_879099276_product_5925962.jpg', 'image_881487935_product_126111824.jpg', 'image_884496659_product_129809790.jpg', 'image_891223536_product_131597581.jpg', 'image_891708180_product_81114643.jpg', 'image_891725942_product_138457978.jpg', 'image_891725998_product_138459977.jpg', 'image_891729120_product_138459015.jpg', 'image_891729814_product_138460774.jpg', 'image_891732671_product_138460493.jpg', 'image_891736821_product_138464231.jpg', 'image_891738274_product_138465060.jpg', 'image_891739856_product_138463294.jpg', 'image_891740976_product_138463871.jpg', 'image_891741366_product_138468949.jpg', 'image_891743753_product_138468520.jpg', 'image_891744268_product_138466610.jpg', 'image_891745568_product_138468817.jpg', 'image_891835020_product_106117926.jpg', 'image_892682242_product_135141750.jpg', 'image_892937913_product_124679036.jpg', 'image_892937966_product_126159434.jpg', 'image_896432874_product_142698225.jpg', 'image_897494766_product_143510140.jpg', 'image_901097569_product_144610449.jpg', 'image_901354743_product_146713508.jpg', 'image_902210668_product_147298882.jpg', 'image_906099813_product_149145060.jpg', 'image_908471550_product_152786580.jpg', 'image_909281142_product_153775792.jpg', 'image_909281199_product_153775881.jpg', 'image_909691819_product_154047460.jpg', 'image_909972848_product_154090380.jpg', 'image_910951795_product_155227143.jpg', 'image_9118030_product_1372815.jpg', 'image_921306268_product_150373667.jpg', 'image_922355701_product_164676664.jpg', 'image_927527365_product_180498882.jpg', 'image_932720118_product_80161913.jpg', 'image_933233801_product_190091338.jpg', 'image_933234195_product_190091494.jpg', 'image_933234253_product_190091483.jpg', 'image_933235167_product_190091612.jpg', 'image_933235887_product_190093308.jpg', 'image_933236801_product_190094193.jpg', 'image_933236823_product_190093231.jpg', 'image_933237084_product_190093399.jpg', 'image_933238947_product_190096182.jpg', 'image_933240320_product_190095037.jpg', 'image_933240999_product_190099957.jpg', 'image_933241968_product_190098899.jpg', 'image_933243692_product_190097879.jpg', 'image_933244426_product_190100552.jpg', 'image_933245076_product_190101189.jpg', 'image_933248181_product_190101470.jpg', 'image_933248348_product_190101877.jpg', 'image_933250107_product_190103590.jpg', 'image_933251547_product_190106631.jpg', 'image_933251899_product_190104382.jpg', 'image_933251978_product_190103729.jpg', 'image_933252797_product_190105847.jpg', 'image_933253436_product_190106777.jpg', 'image_933253491_product_190106341.jpg', 'image_933254552_product_190108765.jpg', 'image_933255053_product_190108376.jpg', 'image_933255934_product_190109589.jpg', 'image_933256073_product_190109266.jpg', 'image_933256325_product_190109294.jpg', 'image_933256367_product_190109245.jpg', 'image_933257401_product_190108311.jpg', 'image_933257534_product_190108918.jpg', 'image_933257981_product_190108812.jpg', 'image_933258353_product_190109959.jpg', 'image_933260225_product_190110715.jpg', 'image_933263084_product_190111725.jpg', 'image_933263666_product_190112670.jpg', 'image_933266207_product_190122195.jpg', 'image_933447173_product_190543353.jpg', 'image_933684149_product_190994440.jpg', 'image_935314259_product_194452799.jpg', 'image_936523476_product_89819109.jpg', 'image_936900015_product_130415468.jpg', 'image_937192623_product_197450909.jpg', 'image_937776943_product_192607595.jpg', 'image_939405656_product_161987876.jpg', 'image_939983893_product_203224746.jpg', 'image_940318369_product_203667517.jpg', 'image_941711858_product_6438248.jpg', 'image_946263596_product_53568396.jpg', 'image_946272989_product_54242252.jpg', 'image_946296536_product_208372596.jpg', 'image_946296632_product_75415120.jpg', 'image_947128283_product_97662640.jpg', 'image_947328613_product_97070180.jpg', 'image_948064881_product_210707049.jpg', 'image_955850685_product_1297834.jpg', 'image_956267541_product_221358684.jpg', 'image_956730229_product_223026420.jpg', 'image_957950713_product_223928273.jpg', 'image_958112438_product_226639108.jpg', 'image_958250965_product_227205580.jpg', 'image_958498859_product_228094884.jpg', 'image_958935293_product_228092929.jpg', 'image_962075798_product_46899777.jpg', 'image_963227279_product_190092264.jpg', 'image_963491300_product_243842296.jpg', 'image_966604797_product_252504330.jpg', 'image_970625645_product_259377999.jpg', 'image_970911889_product_260458769.jpg', 'image_971348084_product_261788917.jpg', 'image_971371809_product_262041682.jpg', 'image_971767481_product_263291107.jpg', 'image_973125188_product_267898588.jpg', 'image_973166956_product_49843653.jpg', 'image_973933517_product_251410352.jpg', 'image_973933825_product_242869160.jpg', 'image_975796552_product_258341670.jpg', 'image_983165270_product_272078964.jpg', 'image_985456698_product_290210516.jpg', 'image_985456723_product_288040998.jpg', 'image_987178672_product_293733323.jpg', 'image_999810411_product_301235593.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Vérifier que le répertoire existe et lister les fichiers\n",
    "image_dir = \"batchs_équilibrés\\\\batch_entrainement\\\\\"\n",
    "\n",
    "print(f\"Vérification des fichiers dans {image_dir} :\")\n",
    "print(os.listdir(image_dir))  # Affiche les fichiers présents dans le répertoire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     image_874729307_product_74244625.jpg\n",
      "1     image_874730792_product_49132716.jpg\n",
      "2     image_874731199_product_74093483.jpg\n",
      "3     image_874731370_product_49948298.jpg\n",
      "4    image_881487935_product_126111824.jpg\n",
      "Name: image_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Afficher les premières lignes pour vérifier les noms d'images\n",
    "print(df['image_name'].head())\n",
    "\n",
    "\n",
    "# Vérifier les noms d'images pour des caractères spéciaux ou invisibles\n",
    "for name in df['image_name']:\n",
    "    try:\n",
    "        name = str(name).encode('utf-8', 'ignore').decode('utf-8', 'ignore')\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Erreur avec le nom de fichier : {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de l'existence des fichiers images\n",
    "for img_name in df[\"image_name\"]:\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    if not os.path.isfile(img_path):\n",
    "        print(img_path)\n",
    "        print(f\"Erreur: L'image suivante est manquante : {img_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚨 Images manquantes : ['image_891725531_product_138457897.jpg', 'image_23276830_product_1533426.jpg', 'image_40504830_product_1788665.jpg', 'image_486903891_product_51173981.jpg', 'image_651743714_product_54844666.jpg', 'image_830635508_product_63004531.jpg', 'image_833130849_product_61985267.jpg', 'image_844644693_product_51529973.jpg', 'image_849076215_product_80378088.jpg', 'image_858567869_product_92021901.jpg', 'image_859921037_product_2923354.jpg', 'image_874537596_product_107645092.jpg', 'image_874538150_product_102311725.jpg', 'image_891727975_product_138459513.jpg', 'image_892247180_product_139269024.jpg', 'image_901354345_product_146713592.jpg', 'image_921363344_product_168669058.jpg', 'image_933233976_product_190091431.jpg', 'image_933234188_product_190091335.jpg', 'image_933252862_product_190106248.jpg', 'image_1018013263_product_508622373.jpg', 'image_1027902744_product_577491837.jpg', 'image_1203606331_product_3280203098.jpg', 'image_1216045204_product_2843201888.jpg', 'image_1237629677_product_3693507395.jpg', 'image_1240338732_product_3746808985.jpg', 'image_1241406561_product_3756592583.jpg', 'image_631246_product_984304.jpg', 'image_1063831_product_1157144.jpg', 'image_137609430_product_1906192.jpg', 'image_158554130_product_1288702.jpg', 'image_197401530_product_5913718.jpg', 'image_310317432_product_46565050.jpg', 'image_438012288_product_49843702.jpg', 'image_858194557_product_92413946.jpg', 'image_874538407_product_102313516.jpg', 'image_508685383_product_52348929.jpg', 'image_933246596_product_190099934.jpg', 'image_875245740_product_120815258.jpg', 'image_890393093_product_112462775.jpg', 'image_891727419_product_138462291.jpg', 'image_905597768_product_125837942.jpg', 'image_933254112_product_190107692.jpg', 'image_933255073_product_190107492.jpg', 'image_933257176_product_190108856.jpg', 'image_933260060_product_190110205.jpg', 'image_955659162_product_220267363.jpg', 'image_956350704_product_221607062.jpg', 'image_956684035_product_222848401.jpg', 'image_967021253_product_98083871.jpg', 'image_972149655_product_56745793.jpg', 'image_972618604_product_2922078.jpg', 'image_1017747635_product_289544125.jpg', 'image_1030684872_product_602135429.jpg', 'image_1085432053_product_1503924395.jpg', 'image_1104042367_product_1683179868.jpg', 'image_933266676_product_190122199.jpg', 'image_962974795_product_242239222.jpg', 'image_977139301_product_125001384.jpg', 'image_1017050069_product_279038476.jpg', 'image_1095254559_product_1187912485.jpg', 'image_137526430_product_3702692.jpg', 'image_159111130_product_3116676.jpg', 'image_849082473_product_80378043.jpg', 'image_857341291_product_91154354.jpg', 'image_879338005_product_98121571.jpg', 'image_891723683_product_138457274.jpg', 'image_891743458_product_138469056.jpg', 'image_933243687_product_190099305.jpg', 'image_933247434_product_190101002.jpg', 'image_1043131773_product_142455913.jpg', 'image_1165669224_product_2806194979.jpg', 'image_1167318682_product_2832777929.jpg', 'image_1193424347_product_3144085232.jpg', 'image_108128830_product_2924143.jpg', 'image_854179992_product_85757275.jpg', 'image_874538300_product_109422166.jpg', 'image_970911880_product_260458764.jpg', 'image_1107916129_product_3716249024.jpg', 'image_1139580082_product_2394819677.jpg', 'image_1193420048_product_3139412813.jpg', 'image_1194596318_product_3150129928.jpg', 'image_1241290050_product_3754982637.jpg', 'image_1100063096_product_1711731907.jpg', 'image_1100064358_product_1711734478.jpg', 'image_1043191722_product_848683457.jpg', 'image_1095315120_product_1634746443.jpg', 'image_1098449903_product_1686387215.jpg', 'image_1099823981_product_1707592368.jpg', 'image_1100064781_product_1711735502.jpg', 'image_1100065667_product_1711736883.jpg', 'image_1100068014_product_1711731452.jpg', 'image_1100068291_product_1711728483.jpg', 'image_1100069905_product_1711734637.jpg', 'image_1100070665_product_1711735991.jpg', 'image_1100072901_product_1711735439.jpg', 'image_1100077219_product_1711735441.jpg', 'image_1100083336_product_1711736982.jpg', 'image_1100249651_product_488318872.jpg', 'image_1108738106_product_1878218325.jpg', 'image_1108738886_product_1878218223.jpg', 'image_1115503666_product_1945991657.jpg', 'image_1124838336_product_2085018125.jpg', 'image_1146884902_product_2525244384.jpg', 'image_1151578632_product_2585832925.jpg', 'image_1154827280_product_2644384305.jpg', 'image_1164819652_product_2795217657.jpg', 'image_1173138897_product_2923358903.jpg', 'image_1225404932_product_3589877929.jpg', 'image_1236934312_product_3716120826.jpg', 'image_1236934740_product_3716121080.jpg', 'image_1236934933_product_3716121412.jpg', 'image_1236935115_product_3716121633.jpg', 'image_1240985666_product_3751708036.jpg', 'image_1264105210_product_3923709336.jpg', 'image_1275879025_product_4009376995.jpg', 'image_167602430_product_1836281.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dir = \"batchs_équilibrés/batch_entrainement - Copie/\"\n",
    "\n",
    "missing_files = []\n",
    "for name in df['image_name']:\n",
    "    img_path = os.path.join(image_dir, name)\n",
    "    if not os.path.exists(img_path):\n",
    "        missing_files.append(name)\n",
    "\n",
    "if missing_files:\n",
    "    print(\"🚨 Images manquantes :\", missing_files)  # Affiche les 10 premières pour éviter trop de spam\n",
    "else:\n",
    "    print(\"✅ Tous les fichiers existent !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom de l'image: b'image_874729307_product_74244625.jpg', Label: 5\n",
      "Nom de l'image: b'image_874730792_product_49132716.jpg', Label: 3\n",
      "Nom de l'image: b'image_874731199_product_74093483.jpg', Label: 6\n",
      "Nom de l'image: b'image_874731370_product_49948298.jpg', Label: 3\n",
      "Nom de l'image: b'image_881487935_product_126111824.jpg', Label: 3\n"
     ]
    }
   ],
   "source": [
    "# Vérifier si le dataset lui-même est correct\n",
    "image_names = df[\"image_name\"].values\n",
    "labels = df[\"category_encoded\"].values\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_names, labels))\n",
    "\n",
    "# Afficher quelques éléments du dataset avant de les passer dans la fonction de chargement\n",
    "for img_name, label in dataset.take(5):  # Prendre les 5 premiers éléments\n",
    "    print(f\"Nom de l'image: {img_name}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image trouvée : batchs_équilibrés\\batch_entrainement\\image_874729307_product_74244625.jpg\n",
      "Image trouvée : batchs_équilibrés\\batch_entrainement\\image_874730792_product_49132716.jpg\n",
      "Image trouvée : batchs_équilibrés\\batch_entrainement\\image_874731199_product_74093483.jpg\n",
      "Image trouvée : batchs_équilibrés\\batch_entrainement\\image_874731370_product_49948298.jpg\n",
      "Image trouvée : batchs_équilibrés\\batch_entrainement\\image_881487935_product_126111824.jpg\n"
     ]
    }
   ],
   "source": [
    "for img_name in image_names[:5]:  # Vérifier les 5 premiers noms d'images\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image non trouvée : {img_path}\")\n",
    "    else:\n",
    "        print(f\"Image trouvée : {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_name, label):\n",
    "    try:\n",
    "        # Nettoyage plus strict des caractères\n",
    "        img_name = img_name.numpy().decode('utf-8', 'ignore')  # Décoder en utf-8 et ignorer les erreurs\n",
    "        \n",
    "        img_path = os.path.join(image_dir, img_name)  # Assurer le bon chemin d'accès\n",
    "        img = tf.io.read_file(img_path)  # Lire l'image avec TensorFlow\n",
    "        img = tf.image.decode_jpeg(img, channels=3)  # Décoder l'image (JPEG) en un Tensor\n",
    "        img = tf.image.resize(img, [224, 224])  # Redimensionner l'image à 224x224\n",
    "        img = img / 255.0  # Normalisation des pixels entre 0 et 1\n",
    "        return img, label\n",
    "    except tf.errors.NotFoundError:\n",
    "        print(f\"Image non trouvée : {img_name}\")  # Afficher une erreur si l'image n'est pas trouvée\n",
    "        return None, label\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Erreur de décodage avec le fichier {img_name}: {e}\")\n",
    "        return None, label\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement de l'image {img_name}: {e}\")\n",
    "        return None, label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
