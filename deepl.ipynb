{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"Batch_2_train_labels_clean.csv\")\n",
    "df2 = pd.read_csv(\"Batch_1_train_labels_clean.csv\")\n",
    "\n",
    "df3 = pd.read_excel(\"image_labels_batch_3.xlsx\")\n",
    "df4 = pd.read_excel(\"image_labels_batch_4.xlsx\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  image_name           category  \\\n",
      "0       image_874729307_product_74244625.jpg          PC Gaming   \n",
      "1       image_874730792_product_49132716.jpg           Nintendo   \n",
      "2       image_874731199_product_74093483.jpg        PlayStation   \n",
      "3       image_874731370_product_49948298.jpg           Nintendo   \n",
      "4      image_881487935_product_126111824.jpg           Nintendo   \n",
      "..                                       ...                ...   \n",
      "346  image_1100063096_product_1711731907.jpg          PC Gaming   \n",
      "347  image_1100063685_product_1711736000.jpg          PC Gaming   \n",
      "348  image_1100064358_product_1711734478.jpg          PC Gaming   \n",
      "349  image_1119523636_product_2000192031.jpg  R√©alit√© Virtuelle   \n",
      "350  image_1139162966_product_2379124886.jpg           Nintendo   \n",
      "\n",
      "               subcategory  \n",
      "0                  Jeux PC  \n",
      "1    Jeux Game Boy Advance  \n",
      "2                 Jeux PS3  \n",
      "3    Jeux Game Boy Advance  \n",
      "4         Jeux Nintendo DS  \n",
      "..                     ...  \n",
      "346                Jeux PC  \n",
      "347                Jeux PC  \n",
      "348                Jeux PC  \n",
      "349             Jeux VR PC  \n",
      "350       Jeux Nintendo DS  \n",
      "\n",
      "[351 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Charger le DataFrame contenant les informations des images et des labels\n",
    "# df = pd.read_csv(\"ton_fichier.csv\")  # Assure-toi que df est d√©j√† charg√© dans ton environnement (avec les colonnes \"image_name\" et \"category\")\n",
    "\n",
    "# D√©finir le dossier contenant les images\n",
    "image_dir = \"Projet_3/batchs_√©quilibr√©s/batch_entrainement/\"\n",
    "\n",
    "# Fonction pour charger une image et son label avec TensorFlow\n",
    "def load_image(img_name, label):\n",
    "    # Construire le chemin complet de l'image avec tf.strings.join\n",
    "    img_path = tf.strings.join([image_dir, img_name])  # Joindre le r√©pertoire et le nom de l'image\n",
    "    img = tf.io.read_file(img_path)  # Lire l'image avec TensorFlow\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # D√©coder l'image (JPEG) en un Tensor\n",
    "    img = tf.image.resize(img, [224, 224])  # Redimensionner l'image √† 224x224\n",
    "    img = img / 255.0  # Normalisation des pixels entre 0 et 1\n",
    "    return img, label\n",
    "\n",
    "# Convertir les noms d'images et labels en TensorFlow Dataset\n",
    "image_names = df[\"image_name\"].values\n",
    "labels = df[\"category_encoded\"].values\n",
    "\n",
    "# Cr√©er un dataset TensorFlow √† partir des chemins d'images et des labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_names, labels))\n",
    "\n",
    "# Appliquer la fonction de chargement d'image et label avec map\n",
    "dataset = dataset.map(lambda x, y: load_image(x, y))\n",
    "\n",
    "# Diviser en batchs, m√©langer et pr√©-charger pour am√©liorer les performances\n",
    "dataset = dataset.batch(32).shuffle(1000).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x92 in position 191: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Entra√Æner le mod√®le\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Sauvegarder le mod√®le\u001b[39;00m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x92 in position 191: invalid start byte"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# D√©finir le mod√®le CNN (Convolutional Neural Network)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(np.unique(labels)), activation='softmax')  # Nombre de classes\n",
    "])\n",
    "\n",
    "# Compiler le mod√®le\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entra√Æner le mod√®le\n",
    "history = model.fit(dataset, epochs=10)\n",
    "\n",
    "# Sauvegarder le mod√®le\n",
    "model.save(\"model.h5\")\n",
    "\n",
    "# Affichage des r√©sultats de l'entra√Ænement\n",
    "print(\"Entra√Ænement termin√©. Le mod√®le a √©t√© sauvegard√© sous 'model.h5'.\")\n",
    "\n",
    "# Si tu souhaites visualiser l'historique de l'entra√Ænement, voici comment :\n",
    "# V√©rifier que les cl√©s 'loss' et 'accuracy' existent dans l'historique\n",
    "if 'accuracy' in history.history:\n",
    "    acc = history.history['accuracy']\n",
    "else:\n",
    "    acc = history.history['accuracy_1']  # Selon la version de TensorFlow, √ßa peut √™tre accuracy_1\n",
    "\n",
    "# Tracer la courbe de perte\n",
    "plt.plot(history.history['loss'], label='Perte (loss)')\n",
    "plt.plot(acc, label='Pr√©cision (accuracy)')\n",
    "plt.title(\"Courbes de l'entra√Ænement\")\n",
    "plt.xlabel(\"√âpoques\")\n",
    "plt.ylabel(\"Valeur\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 194: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Compiler et tester l'entra√Ænement avec un mod√®le plus simple\u001b[39;00m\n\u001b[0;32m     82\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 84\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Sauvegarder le mod√®le\u001b[39;00m\n\u001b[0;32m     88\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 194: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Lire les fichiers CSV en utilisant un encodage correct\n",
    "try:\n",
    "    df1 = pd.read_csv(\"Batch_2_train_labels_clean.csv\", encoding='utf-8')\n",
    "    df2 = pd.read_csv(\"Batch_1_train_labels_clean.csv\", encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df1 = pd.read_csv(\"Batch_2_train_labels_clean.csv\", encoding='utf-8', errors='ignore')\n",
    "    df2 = pd.read_csv(\"Batch_1_train_labels_clean.csv\", encoding='utf-8', errors='ignore')\n",
    "\n",
    "df3 = pd.read_excel(\"image_labels_batch_3.xlsx\", engine='openpyxl')\n",
    "df4 = pd.read_excel(\"image_labels_batch_4.xlsx\", engine='openpyxl')\n",
    "\n",
    "# Fusionner les DataFrames\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "\n",
    "# Encoder les cat√©gories en valeurs num√©riques\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "# D√©finir le dossier contenant les images\n",
    "image_dir = \"batchs_√©quilibr√©s\\\\batch_entrainement - Copie\\\\\"\n",
    "\n",
    "\n",
    "def load_image(img_name, label):\n",
    "    try:\n",
    "        # Utiliser tf.py_function pour s'assurer que l'on travaille avec une cha√Æne et non un tenseur\n",
    "        img_name_str = tf.py_function(lambda x: x.numpy().decode('utf-8'), [img_name], Tout=tf.string)\n",
    "\n",
    "        img_path = tf.strings.join([image_dir, img_name_str])  # Construire le chemin complet\n",
    "        img = tf.io.read_file(img_path)  # Lire l'image\n",
    "        img = tf.image.decode_jpeg(img, channels=3)  # D√©coder l'image\n",
    "        img = tf.image.resize(img, [224, 224])  # Redimensionner l'image\n",
    "        img = img / 255.0  # Normaliser l'image\n",
    "        return img, label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement de l'image {img_name}: {e}\")\n",
    "        return tf.zeros([224, 224, 3]), label  # Retourner une image vide au lieu de None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def filter_invalid_images(img, label):\n",
    "    \"\"\"Filtrer les images invalides.\"\"\"\n",
    "    return img is not None\n",
    "\n",
    "# Convertir les noms d'images et labels en TensorFlow Dataset\n",
    "image_names = df[\"image_name\"].values\n",
    "labels = df[\"category_encoded\"].values\n",
    "\n",
    "# Cr√©er un dataset TensorFlow √† partir des chemins d'images et des labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_names, labels))\n",
    "\n",
    "# Appliquer la fonction de chargement d'image et label avec map\n",
    "dataset = dataset.map(lambda x, y: load_image(x, y))\n",
    "\n",
    "# Filtrer les images invalides\n",
    "dataset = dataset.filter(filter_invalid_images)\n",
    "\n",
    "# Diviser en batchs, m√©langer et pr√©-charger pour am√©liorer les performances\n",
    "dataset = dataset.batch(32).shuffle(1000).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Mod√®le simplifi√© pour tester\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(len(np.unique(labels)), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiler et tester l'entra√Ænement avec un mod√®le plus simple\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(dataset, epochs=1)\n",
    "\n",
    "\n",
    "# Sauvegarder le mod√®le\n",
    "model.save(\"model.h5\")\n",
    "\n",
    "# Affichage des r√©sultats de l'entra√Ænement\n",
    "print(\"Entra√Ænement termin√©. Le mod√®le a √©t√© sauvegard√© sous 'model.h5'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V√©rification des fichiers dans batchs_√©quilibr√©s\\batch_entrainement\\ :\n",
      "['image_1000493202_product_353771692.jpg', 'image_1004469307_product_299520596.jpg', 'image_1016066453_product_493545596.jpg', 'image_1025231310_product_436182917.jpg', 'image_1027953365_product_301940235.jpg', 'image_1027961004_product_578256383.jpg', 'image_1032783160_product_630642988.jpg', 'image_1039267141_product_646789701.jpg', 'image_1041335988_product_825941638.jpg', 'image_1041415174_product_826453416.jpg', 'image_1041748138_product_832656848.jpg', 'image_1044577992_product_861269059.jpg', 'image_1049879107_product_957011147.jpg', 'image_1051593_product_1283013.jpg', 'image_1053085531_product_1022623650.jpg', 'image_1053259382_product_1028931562.jpg', 'image_1053519738_product_1033730640.jpg', 'image_1058972548_product_1089685811.jpg', 'image_1062523736_product_301815907.jpg', 'image_1068150012_product_1132613553.jpg', 'image_1068227670_product_1190608934.jpg', 'image_1068342_product_3108655.jpg', 'image_1073717173_product_1324193385.jpg', 'image_1075005845_product_1139865005.jpg', 'image_1077931399_product_1029033291.jpg', 'image_1096911277_product_1638225913.jpg', 'image_1098376627_product_1684789300.jpg', 'image_1100059921_product_1711736573.jpg', 'image_1100059985_product_1711729477.jpg', 'image_1100062722_product_1711729209.jpg', 'image_1100063685_product_1711736000.jpg', 'image_1100064150_product_1711734470.jpg', 'image_1100065101_product_1711733299.jpg', 'image_1100065729_product_1711730415.jpg', 'image_1100065974_product_1711736557.jpg', 'image_1100066181_product_1711734926.jpg', 'image_1100066237_product_1711735656.jpg', 'image_1100066257_product_1711735869.jpg', 'image_1100066292_product_1711728922.jpg', 'image_1100066810_product_1711736554.jpg', 'image_1100066842_product_1711728920.jpg', 'image_1100068625_product_1711735034.jpg', 'image_1100069166_product_1711734525.jpg', 'image_1100070218_product_1711734642.jpg', 'image_1100070334_product_1711733251.jpg', 'image_1100071411_product_1711730412.jpg', 'image_1100073107_product_1711735590.jpg', 'image_1100073842_product_1711735498.jpg', 'image_1100076011_product_1711736387.jpg', 'image_1100076297_product_1711730104.jpg', 'image_1100076669_product_1711736594.jpg', 'image_1100076852_product_1711728854.jpg', 'image_1100077047_product_1711736577.jpg', 'image_1100077500_product_1711734807.jpg', 'image_1100077520_product_1711736784.jpg', 'image_1100077574_product_1711735833.jpg', 'image_1100077949_product_1711736055.jpg', 'image_1100081021_product_1711736636.jpg', 'image_1100081308_product_1711735062.jpg', 'image_1100081813_product_1711736882.jpg', 'image_1100081873_product_1711736649.jpg', 'image_1100081963_product_1711731563.jpg', 'image_1100082443_product_1711730037.jpg', 'image_1100083267_product_1711729062.jpg', 'image_1100083741_product_1711736282.jpg', 'image_1100085244_product_1711736828.jpg', 'image_1100086947_product_1711736338.jpg', 'image_1102674938_product_1805032545.jpg', 'image_110307330_product_1198135.jpg', 'image_1108215009_product_1871867473.jpg', 'image_1108316109_product_1874931038.jpg', 'image_1108365016_product_1875756839.jpg', 'image_1108365346_product_1875804585.jpg', 'image_1108365418_product_1875756849.jpg', 'image_1108365425_product_1875804608.jpg', 'image_1108737984_product_1878218298.jpg', 'image_1108738672_product_1878218172.jpg', 'image_1108738842_product_1878218230.jpg', 'image_1108738856_product_1878218295.jpg', 'image_1110810102_product_1904422813.jpg', 'image_1115683575_product_1949003999.jpg', 'image_1116698200_product_1963983036.jpg', 'image_1117041866_product_1967323837.jpg', 'image_1119523636_product_2000192031.jpg', 'image_1121512302_product_2032256097.jpg', 'image_1123495532_product_1936795860.jpg', 'image_1123660911_product_2060555800.jpg', 'image_1130418886_product_2184281904.jpg', 'image_1132925383_product_2237358098.jpg', 'image_1132983627_product_2240360476.jpg', 'image_1132983697_product_2240360489.jpg', 'image_1132983863_product_2240360521.jpg', 'image_1133950997_product_2034871712.jpg', 'image_1134177075_product_2275732341.jpg', 'image_1134618245_product_2287962051.jpg', 'image_1139162966_product_2379124886.jpg', 'image_1141465108_product_2432859218.jpg', 'image_1142916338_product_3910575.jpg', 'image_1143577545_product_2467914465.jpg', 'image_1146083530_product_2151614761.jpg', 'image_1146981061_product_2527236596.jpg', 'image_1148926787_product_2550005949.jpg', 'image_1149450149_product_2036108212.jpg', 'image_1152030349_product_2596981190.jpg', 'image_1158045210_product_2694313750.jpg', 'image_1159838466_product_2720289759.jpg', 'image_1159838467_product_2720289758.jpg', 'image_1160912325_product_2726077368.jpg', 'image_1161168397_product_2733520304.jpg', 'image_1168313731_product_2856775404.jpg', 'image_1176898982_product_2964292933.jpg', 'image_1176954743_product_2965041516.jpg', 'image_1178140299_product_2807747392.jpg', 'image_1183024584_product_3010870346.jpg', 'image_1186985707_product_3040901566.jpg', 'image_1187911797_product_3058415833.jpg', 'image_1195977838_product_3179266037.jpg', 'image_1196604463_product_3108206564.jpg', 'image_1199617908_product_3233258914.jpg', 'image_1211700782_product_3250210074.jpg', 'image_1215651393_product_3471354509.jpg', 'image_1225786777_product_3592267416.jpg', 'image_1231976657_product_3656477301.jpg', 'image_1233470015_product_3626367914.jpg', 'image_1234513943_product_3684576397.jpg', 'image_1234808632_product_3690853420.jpg', 'image_1235567047_product_3695632560.jpg', 'image_1236934329_product_3716121060.jpg', 'image_1236934770_product_3716121141.jpg', 'image_1236934931_product_3716121410.jpg', 'image_1236934944_product_3716121425.jpg', 'image_1236935361_product_3716121933.jpg', 'image_1236944545_product_3716248639.jpg', 'image_1240554261_product_3748316863.jpg', 'image_1241398257_product_3756587883.jpg', 'image_1246419210_product_3797495566.jpg', 'image_1247153473_product_3805769836.jpg', 'image_1268084489_product_3906702928.jpg', 'image_1268253920_product_1585204775.jpg', 'image_1268904663_product_3947920720.jpg', 'image_1280048988_product_4042765839.jpg', 'image_1285449640_product_4042892616.jpg', 'image_1301143063_product_4150865160.jpg', 'image_1302204660_product_4154117441.jpg', 'image_1315355210_product_4205293139.jpg', 'image_1315763371_product_4206711456.jpg', 'image_13233030_product_1431728.jpg', 'image_134067230_product_2920625.jpg', 'image_234303430_product_6648556.jpg', 'image_251865378_product_7980077.jpg', 'image_283812671_product_15511645.jpg', 'image_300773669_product_2532960.jpg', 'image_300917069_product_928105.jpg', 'image_301844443_product_5189935.jpg', 'image_30320630_product_1663769.jpg', 'image_308038846_product_1607404.jpg', 'image_319050191_product_46845576.jpg', 'image_324151298_product_14034577.jpg', 'image_328927145_product_927741.jpg', 'image_334877360_product_47896567.jpg', 'image_347816633_product_48336271.jpg', 'image_381381976_product_49628162.jpg', 'image_438013740_product_48575623.jpg', 'image_476359610_product_1853453.jpg', 'image_476581624_product_2990280.jpg', 'image_529140_product_923202.jpg', 'image_54547530_product_929584.jpg', 'image_558592269_product_53702264.jpg', 'image_564455330_product_49848465.jpg', 'image_583198100_product_54284822.jpg', 'image_622938810_product_1172613.jpg', 'image_62364030_product_1559752.jpg', 'image_62369530_product_2242928.jpg', 'image_652832876_product_53217499.jpg', 'image_659698_product_822774.jpg', 'image_659788_product_1018391.jpg', 'image_689615053_product_56875966.jpg', 'image_689649164_product_184794.jpg', 'image_712678422_product_1586816.jpg', 'image_716950448_product_7490474.jpg', 'image_729787_product_1069161.jpg', 'image_77378530_product_1511251.jpg', 'image_79506330_product_2628871.jpg', 'image_821752779_product_62539070.jpg', 'image_834625716_product_2922066.jpg', 'image_845665195_product_74697205.jpg', 'image_846014108_product_75096137.jpg', 'image_846909214_product_76281501.jpg', 'image_847403454_product_76335437.jpg', 'image_848934197_product_80184781.jpg', 'image_848934236_product_80184839.jpg', 'image_848934532_product_80185024.jpg', 'image_849650304_product_81124208.jpg', 'image_852972374_product_80220190.jpg', 'image_854179052_product_85756666.jpg', 'image_857279564_product_2922637.jpg', 'image_858267336_product_80597800.jpg', 'image_858283719_product_92572816.jpg', 'image_862620327_product_102967842.jpg', 'image_867095986_product_55556886.jpg', 'image_871216205_product_115839088.jpg', 'image_871483952_product_115419768.jpg', 'image_873763964_product_119565640.jpg', 'image_873981549_product_119753971.jpg', 'image_874237655_product_119941493.jpg', 'image_874537621_product_107645356.jpg', 'image_874538053_product_111847660.jpg', 'image_874538275_product_105665622.jpg', 'image_874538397_product_111096070.jpg', 'image_874714971_product_1766378.jpg', 'image_874726355_product_50692880.jpg', 'image_874727855_product_99505596.jpg', 'image_874727878_product_90062129.jpg', 'image_874728161_product_82614930.jpg', 'image_874728237_product_60669170.jpg', 'image_874728473_product_82088950.jpg', 'image_874728837_product_97517744.jpg', 'image_874729026_product_77765803.jpg', 'image_874729307_product_74244625.jpg', 'image_874729653_product_65150348.jpg', 'image_874729700_product_51838314.jpg', 'image_874730026_product_46615098.jpg', 'image_874730352_product_82272428.jpg', 'image_874730792_product_49132716.jpg', 'image_874730967_product_71079705.jpg', 'image_874731199_product_74093483.jpg', 'image_874731282_product_76560739.jpg', 'image_874731286_product_46704360.jpg', 'image_874731370_product_49948298.jpg', 'image_879099276_product_5925962.jpg', 'image_881487935_product_126111824.jpg', 'image_884496659_product_129809790.jpg', 'image_891223536_product_131597581.jpg', 'image_891708180_product_81114643.jpg', 'image_891725942_product_138457978.jpg', 'image_891725998_product_138459977.jpg', 'image_891729120_product_138459015.jpg', 'image_891729814_product_138460774.jpg', 'image_891732671_product_138460493.jpg', 'image_891736821_product_138464231.jpg', 'image_891738274_product_138465060.jpg', 'image_891739856_product_138463294.jpg', 'image_891740976_product_138463871.jpg', 'image_891741366_product_138468949.jpg', 'image_891743753_product_138468520.jpg', 'image_891744268_product_138466610.jpg', 'image_891745568_product_138468817.jpg', 'image_891835020_product_106117926.jpg', 'image_892682242_product_135141750.jpg', 'image_892937913_product_124679036.jpg', 'image_892937966_product_126159434.jpg', 'image_896432874_product_142698225.jpg', 'image_897494766_product_143510140.jpg', 'image_901097569_product_144610449.jpg', 'image_901354743_product_146713508.jpg', 'image_902210668_product_147298882.jpg', 'image_906099813_product_149145060.jpg', 'image_908471550_product_152786580.jpg', 'image_909281142_product_153775792.jpg', 'image_909281199_product_153775881.jpg', 'image_909691819_product_154047460.jpg', 'image_909972848_product_154090380.jpg', 'image_910951795_product_155227143.jpg', 'image_9118030_product_1372815.jpg', 'image_921306268_product_150373667.jpg', 'image_922355701_product_164676664.jpg', 'image_927527365_product_180498882.jpg', 'image_932720118_product_80161913.jpg', 'image_933233801_product_190091338.jpg', 'image_933234195_product_190091494.jpg', 'image_933234253_product_190091483.jpg', 'image_933235167_product_190091612.jpg', 'image_933235887_product_190093308.jpg', 'image_933236801_product_190094193.jpg', 'image_933236823_product_190093231.jpg', 'image_933237084_product_190093399.jpg', 'image_933238947_product_190096182.jpg', 'image_933240320_product_190095037.jpg', 'image_933240999_product_190099957.jpg', 'image_933241968_product_190098899.jpg', 'image_933243692_product_190097879.jpg', 'image_933244426_product_190100552.jpg', 'image_933245076_product_190101189.jpg', 'image_933248181_product_190101470.jpg', 'image_933248348_product_190101877.jpg', 'image_933250107_product_190103590.jpg', 'image_933251547_product_190106631.jpg', 'image_933251899_product_190104382.jpg', 'image_933251978_product_190103729.jpg', 'image_933252797_product_190105847.jpg', 'image_933253436_product_190106777.jpg', 'image_933253491_product_190106341.jpg', 'image_933254552_product_190108765.jpg', 'image_933255053_product_190108376.jpg', 'image_933255934_product_190109589.jpg', 'image_933256073_product_190109266.jpg', 'image_933256325_product_190109294.jpg', 'image_933256367_product_190109245.jpg', 'image_933257401_product_190108311.jpg', 'image_933257534_product_190108918.jpg', 'image_933257981_product_190108812.jpg', 'image_933258353_product_190109959.jpg', 'image_933260225_product_190110715.jpg', 'image_933263084_product_190111725.jpg', 'image_933263666_product_190112670.jpg', 'image_933266207_product_190122195.jpg', 'image_933447173_product_190543353.jpg', 'image_933684149_product_190994440.jpg', 'image_935314259_product_194452799.jpg', 'image_936523476_product_89819109.jpg', 'image_936900015_product_130415468.jpg', 'image_937192623_product_197450909.jpg', 'image_937776943_product_192607595.jpg', 'image_939405656_product_161987876.jpg', 'image_939983893_product_203224746.jpg', 'image_940318369_product_203667517.jpg', 'image_941711858_product_6438248.jpg', 'image_946263596_product_53568396.jpg', 'image_946272989_product_54242252.jpg', 'image_946296536_product_208372596.jpg', 'image_946296632_product_75415120.jpg', 'image_947128283_product_97662640.jpg', 'image_947328613_product_97070180.jpg', 'image_948064881_product_210707049.jpg', 'image_955850685_product_1297834.jpg', 'image_956267541_product_221358684.jpg', 'image_956730229_product_223026420.jpg', 'image_957950713_product_223928273.jpg', 'image_958112438_product_226639108.jpg', 'image_958250965_product_227205580.jpg', 'image_958498859_product_228094884.jpg', 'image_958935293_product_228092929.jpg', 'image_962075798_product_46899777.jpg', 'image_963227279_product_190092264.jpg', 'image_963491300_product_243842296.jpg', 'image_966604797_product_252504330.jpg', 'image_970625645_product_259377999.jpg', 'image_970911889_product_260458769.jpg', 'image_971348084_product_261788917.jpg', 'image_971371809_product_262041682.jpg', 'image_971767481_product_263291107.jpg', 'image_973125188_product_267898588.jpg', 'image_973166956_product_49843653.jpg', 'image_973933517_product_251410352.jpg', 'image_973933825_product_242869160.jpg', 'image_975796552_product_258341670.jpg', 'image_983165270_product_272078964.jpg', 'image_985456698_product_290210516.jpg', 'image_985456723_product_288040998.jpg', 'image_987178672_product_293733323.jpg', 'image_999810411_product_301235593.jpg']\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier que le r√©pertoire existe et lister les fichiers\n",
    "image_dir = \"batchs_√©quilibr√©s\\\\batch_entrainement\\\\\"\n",
    "\n",
    "print(f\"V√©rification des fichiers dans {image_dir} :\")\n",
    "print(os.listdir(image_dir))  # Affiche les fichiers pr√©sents dans le r√©pertoire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     image_874729307_product_74244625.jpg\n",
      "1     image_874730792_product_49132716.jpg\n",
      "2     image_874731199_product_74093483.jpg\n",
      "3     image_874731370_product_49948298.jpg\n",
      "4    image_881487935_product_126111824.jpg\n",
      "Name: image_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Afficher les premi√®res lignes pour v√©rifier les noms d'images\n",
    "print(df['image_name'].head())\n",
    "\n",
    "\n",
    "# V√©rifier les noms d'images pour des caract√®res sp√©ciaux ou invisibles\n",
    "for name in df['image_name']:\n",
    "    try:\n",
    "        name = str(name).encode('utf-8', 'ignore').decode('utf-8', 'ignore')\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Erreur avec le nom de fichier : {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification de l'existence des fichiers images\n",
    "for img_name in df[\"image_name\"]:\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    if not os.path.isfile(img_path):\n",
    "        print(img_path)\n",
    "        print(f\"Erreur: L'image suivante est manquante : {img_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Images manquantes : ['image_891725531_product_138457897.jpg', 'image_23276830_product_1533426.jpg', 'image_40504830_product_1788665.jpg', 'image_486903891_product_51173981.jpg', 'image_651743714_product_54844666.jpg', 'image_830635508_product_63004531.jpg', 'image_833130849_product_61985267.jpg', 'image_844644693_product_51529973.jpg', 'image_849076215_product_80378088.jpg', 'image_858567869_product_92021901.jpg', 'image_859921037_product_2923354.jpg', 'image_874537596_product_107645092.jpg', 'image_874538150_product_102311725.jpg', 'image_891727975_product_138459513.jpg', 'image_892247180_product_139269024.jpg', 'image_901354345_product_146713592.jpg', 'image_921363344_product_168669058.jpg', 'image_933233976_product_190091431.jpg', 'image_933234188_product_190091335.jpg', 'image_933252862_product_190106248.jpg', 'image_1018013263_product_508622373.jpg', 'image_1027902744_product_577491837.jpg', 'image_1203606331_product_3280203098.jpg', 'image_1216045204_product_2843201888.jpg', 'image_1237629677_product_3693507395.jpg', 'image_1240338732_product_3746808985.jpg', 'image_1241406561_product_3756592583.jpg', 'image_631246_product_984304.jpg', 'image_1063831_product_1157144.jpg', 'image_137609430_product_1906192.jpg', 'image_158554130_product_1288702.jpg', 'image_197401530_product_5913718.jpg', 'image_310317432_product_46565050.jpg', 'image_438012288_product_49843702.jpg', 'image_858194557_product_92413946.jpg', 'image_874538407_product_102313516.jpg', 'image_508685383_product_52348929.jpg', 'image_933246596_product_190099934.jpg', 'image_875245740_product_120815258.jpg', 'image_890393093_product_112462775.jpg', 'image_891727419_product_138462291.jpg', 'image_905597768_product_125837942.jpg', 'image_933254112_product_190107692.jpg', 'image_933255073_product_190107492.jpg', 'image_933257176_product_190108856.jpg', 'image_933260060_product_190110205.jpg', 'image_955659162_product_220267363.jpg', 'image_956350704_product_221607062.jpg', 'image_956684035_product_222848401.jpg', 'image_967021253_product_98083871.jpg', 'image_972149655_product_56745793.jpg', 'image_972618604_product_2922078.jpg', 'image_1017747635_product_289544125.jpg', 'image_1030684872_product_602135429.jpg', 'image_1085432053_product_1503924395.jpg', 'image_1104042367_product_1683179868.jpg', 'image_933266676_product_190122199.jpg', 'image_962974795_product_242239222.jpg', 'image_977139301_product_125001384.jpg', 'image_1017050069_product_279038476.jpg', 'image_1095254559_product_1187912485.jpg', 'image_137526430_product_3702692.jpg', 'image_159111130_product_3116676.jpg', 'image_849082473_product_80378043.jpg', 'image_857341291_product_91154354.jpg', 'image_879338005_product_98121571.jpg', 'image_891723683_product_138457274.jpg', 'image_891743458_product_138469056.jpg', 'image_933243687_product_190099305.jpg', 'image_933247434_product_190101002.jpg', 'image_1043131773_product_142455913.jpg', 'image_1165669224_product_2806194979.jpg', 'image_1167318682_product_2832777929.jpg', 'image_1193424347_product_3144085232.jpg', 'image_108128830_product_2924143.jpg', 'image_854179992_product_85757275.jpg', 'image_874538300_product_109422166.jpg', 'image_970911880_product_260458764.jpg', 'image_1107916129_product_3716249024.jpg', 'image_1139580082_product_2394819677.jpg', 'image_1193420048_product_3139412813.jpg', 'image_1194596318_product_3150129928.jpg', 'image_1241290050_product_3754982637.jpg', 'image_1100063096_product_1711731907.jpg', 'image_1100064358_product_1711734478.jpg', 'image_1043191722_product_848683457.jpg', 'image_1095315120_product_1634746443.jpg', 'image_1098449903_product_1686387215.jpg', 'image_1099823981_product_1707592368.jpg', 'image_1100064781_product_1711735502.jpg', 'image_1100065667_product_1711736883.jpg', 'image_1100068014_product_1711731452.jpg', 'image_1100068291_product_1711728483.jpg', 'image_1100069905_product_1711734637.jpg', 'image_1100070665_product_1711735991.jpg', 'image_1100072901_product_1711735439.jpg', 'image_1100077219_product_1711735441.jpg', 'image_1100083336_product_1711736982.jpg', 'image_1100249651_product_488318872.jpg', 'image_1108738106_product_1878218325.jpg', 'image_1108738886_product_1878218223.jpg', 'image_1115503666_product_1945991657.jpg', 'image_1124838336_product_2085018125.jpg', 'image_1146884902_product_2525244384.jpg', 'image_1151578632_product_2585832925.jpg', 'image_1154827280_product_2644384305.jpg', 'image_1164819652_product_2795217657.jpg', 'image_1173138897_product_2923358903.jpg', 'image_1225404932_product_3589877929.jpg', 'image_1236934312_product_3716120826.jpg', 'image_1236934740_product_3716121080.jpg', 'image_1236934933_product_3716121412.jpg', 'image_1236935115_product_3716121633.jpg', 'image_1240985666_product_3751708036.jpg', 'image_1264105210_product_3923709336.jpg', 'image_1275879025_product_4009376995.jpg', 'image_167602430_product_1836281.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dir = \"batchs_√©quilibr√©s/batch_entrainement - Copie/\"\n",
    "\n",
    "missing_files = []\n",
    "for name in df['image_name']:\n",
    "    img_path = os.path.join(image_dir, name)\n",
    "    if not os.path.exists(img_path):\n",
    "        missing_files.append(name)\n",
    "\n",
    "if missing_files:\n",
    "    print(\"üö® Images manquantes :\", missing_files)  # Affiche les 10 premi√®res pour √©viter trop de spam\n",
    "else:\n",
    "    print(\"‚úÖ Tous les fichiers existent !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom de l'image: b'image_874729307_product_74244625.jpg', Label: 5\n",
      "Nom de l'image: b'image_874730792_product_49132716.jpg', Label: 3\n",
      "Nom de l'image: b'image_874731199_product_74093483.jpg', Label: 6\n",
      "Nom de l'image: b'image_874731370_product_49948298.jpg', Label: 3\n",
      "Nom de l'image: b'image_881487935_product_126111824.jpg', Label: 3\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier si le dataset lui-m√™me est correct\n",
    "image_names = df[\"image_name\"].values\n",
    "labels = df[\"category_encoded\"].values\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_names, labels))\n",
    "\n",
    "# Afficher quelques √©l√©ments du dataset avant de les passer dans la fonction de chargement\n",
    "for img_name, label in dataset.take(5):  # Prendre les 5 premiers √©l√©ments\n",
    "    print(f\"Nom de l'image: {img_name}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image trouv√©e : batchs_√©quilibr√©s\\batch_entrainement\\image_874729307_product_74244625.jpg\n",
      "Image trouv√©e : batchs_√©quilibr√©s\\batch_entrainement\\image_874730792_product_49132716.jpg\n",
      "Image trouv√©e : batchs_√©quilibr√©s\\batch_entrainement\\image_874731199_product_74093483.jpg\n",
      "Image trouv√©e : batchs_√©quilibr√©s\\batch_entrainement\\image_874731370_product_49948298.jpg\n",
      "Image trouv√©e : batchs_√©quilibr√©s\\batch_entrainement\\image_881487935_product_126111824.jpg\n"
     ]
    }
   ],
   "source": [
    "for img_name in image_names[:5]:  # V√©rifier les 5 premiers noms d'images\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image non trouv√©e : {img_path}\")\n",
    "    else:\n",
    "        print(f\"Image trouv√©e : {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_name, label):\n",
    "    try:\n",
    "        # Nettoyage plus strict des caract√®res\n",
    "        img_name = img_name.numpy().decode('utf-8', 'ignore')  # D√©coder en utf-8 et ignorer les erreurs\n",
    "        \n",
    "        img_path = os.path.join(image_dir, img_name)  # Assurer le bon chemin d'acc√®s\n",
    "        img = tf.io.read_file(img_path)  # Lire l'image avec TensorFlow\n",
    "        img = tf.image.decode_jpeg(img, channels=3)  # D√©coder l'image (JPEG) en un Tensor\n",
    "        img = tf.image.resize(img, [224, 224])  # Redimensionner l'image √† 224x224\n",
    "        img = img / 255.0  # Normalisation des pixels entre 0 et 1\n",
    "        return img, label\n",
    "    except tf.errors.NotFoundError:\n",
    "        print(f\"Image non trouv√©e : {img_name}\")  # Afficher une erreur si l'image n'est pas trouv√©e\n",
    "        return None, label\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Erreur de d√©codage avec le fichier {img_name}: {e}\")\n",
    "        return None, label\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement de l'image {img_name}: {e}\")\n",
    "        return None, label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
